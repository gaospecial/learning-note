# 神经网络 {#neural-network}

## 神经网络的基本概念 {#concept-of-neural-network}

### 神经元

神经元是神经网络的基本单元。一个神经元由输入端、组合函数、激活函数、输出端组成。组合函数和激活函数是神经网络的核心。

```{r fig.cap="神经元的结构"}
knitr::include_graphics("https://vnote-1251564393.cos.ap-chengdu.myqcloud.com/typora-img/20220420092837.png")
```

人工神经元是一个基于生物神经元的数学模型，神经元接受多个输入信息，对它们进行加权求和，再经过一个激活函数处理，然后将这个结果输出。

对于神经网络而言，神经元节点本身相当于一个神经细胞，输入相当于树突，带权重的连接相当于轴突，输出相当于突触[^neural-network-1]。

[^neural-network-1]: 关于神经网络的更多知识，请参见 <https://www.qikegu.com/docs/3719>。

### 多层感知器

多个神经元连接在一起就形成了神经网络。多层感知器是一种常用的神经网络。各个自变量通过输入层的神经元输入到网络，输入层的输出传递给隐藏层，作为后者的输入；数据经过多个隐藏层的传递后，最终被转换后的数据在输出层形成输出值。

多层感知器通常在隐藏层使用线性组合函数和 S 型激活函数，在输出层使用线性组合函数和与因变量相适应的激活函数。

多层感知器可以形成很复杂的非线性模型。只要给予足够的数据、隐藏层和训练时间，含一层隐藏层的多层感知器就能够以任意精确度近似自变量和因变量之间几乎任何形式的函数；使用多个隐藏层可能用更少的隐藏神经元和参数就能形成复杂的非线性模型，提高模型的泛化能力[^neural-network-2]。

[^neural-network-2]: 是指机器学习算法对新鲜样本的适应能力。 学习的目的是学到隐含在数据背后的规律，对具有同一规律的学习集以外的数据，经过训练的网络也能给出合适的输出，该能力称为泛化能力。

除了多层感知器，常见的神经网络还包括：卷积神经网络、循环神经网络等。卷积神经网络（CNN）旨在解决图像识别问题，卷积神经网络在图像识别、推荐系统以及自然语言处理等方面有着广泛的应用。循环神经网络在语音识别、生成图像描述、音乐合成和机器翻译等领域有着广泛的应用。

不同类型的神经网络都是由多个神经元连接而成的，其主要区别在于神经元的连接规则不同。

对于多层感知器而言，其连接规则为：

-   神经元按照层来布局。最左边的输入层，负责接收输入数据；最右边的输出层，负责输出数据。
-   中间是隐藏层，对于外部不可见。隐藏层可以包含多层，大于一层的就被称为深度神经网络，层次越多数据处理能力越强。
-   同一层的神经元之间没有连接。
-   前后两层的所有神经元相连，前层神经元的输出就是后层神经元的输入。
-   每个连接都有一个权值。

```{r}
knitr::include_graphics("https://vnote-1251564393.cos.ap-chengdu.myqcloud.com/typora-img/20220420100007.png")
```

### 组合函数和激活函数

组合函数通常用线性组合函数，其实就是一个简单的按权重加和。

$$u_j = \sum(v_1, ..., v_s) = b_j + \sum_{r=1}^sw_{rj}v_r$$

激活函数是非线性函数，对组合函数的结果进行处理。它的可选类型比较多，主要有：

-   S 型函数

    -   Logistic 函数：$y = \frac{1}{1+e^{-x}} \in (0, 1)$
    -   Tanh 函数（双曲正切函数）：$y = 1 - \frac{2}{1+e^{2x}} \in (-1, 1)$
    -   Eliot 函数（Softsign 函数）：$y = \frac{x}{1+|x|} \in (-1, 1)$
    -   Arctan 函数：$y = \frac{2}{\pi}arctan(x) \in (-1,1)$

-   ReLU 函数（线性整流函数）：\@ref(eq:relu)

$$\begin{equation}
f(x) = 
\begin{cases} 
x  & \text{if } x \geq 0 \\
0  & \text{if } x < 0
\end{cases}
(\#eq:relu)
\end{equation}$$


- Softmax 函数：$y_j = \frac{e^{u_j}}{\sum_{j'=1}^je^{u_{j'}}} \in (0,1)$

与 S 型函数和 ReLu 函数不同，Softmax 函数是多变量输入激活函数。Softmax 与正常的 max 函数不同：max 函数仅输出最大值，但 Softmax 确保较小的值具有较小的概率，并且不会直接丢弃。

这些激活函数都能将组合函数产生的 $(-\infty, \infty)$ 通过单调连续的非线性转换变成有限的输出值。每种函数在运算速度、可微性、输出值等方面存在差异，因此具有不同的应用场景。

### 神经网络的训练

神经网络的训练，就是求解组合函数权重的过程。简单来说就是从基于误差函数，对权重值不断进行修正，最终是误差逐渐趋近为 0 的过程。误差函数越小，模型拟合效果越好。

根据因变量的取值类型，要在输出层选用不同的激活函数。

- 因变量是二值变量或比例，输出层激活函数采用 Logistic 函数；
- 因变量是多种取值的定类变量，输出层激活函数使用 Softmax 函数或 Logistic 函数；
- 因变量是多种取值的定序变量，可将其看做定类变量，或者根据多个输出单元的结果进行定序；
- 因变量为计数变量（事件发生的次数），输出层的激活函数采用指数函数；
- 因变量为取值可正可负的连续变量（如满足正态分布的数值），输出层激活函数采用恒等函数；
- 因变量为非负连续变量（如收入、销售额），通常将因变量进行 Box-Cox 转换后，在使用因变量可正可负的方法。

*这部分内容解释起来比较复杂，暂且略过*

## 使用神经网络预测红酒品质

`ch7_wine.csv` 记录了与红酒品质相关的 12 个变量，分别是：

- fixed.acidity：固定酸度
- volatile.acidity：挥发性酸度
- citric.acid：柠檬酸
- residual.sugar：残留的糖分
- chlorides：氯化物
- free.sulfur.dioxide：游离二氧化硫
- total.sulfur.dioxide：总二氧化硫
- density：密度
- pH：酸碱度
- sulphates：硫酸盐
- alcohol：酒精度
- quality：**因变量**，品质等级，取值 3 - 9。


## 安装 TensorFlow

[SNNS](http://www.ra.cs.uni-tuebingen.de/SNNS/welcome.html) 是一个经典的神经网络模拟器，本书采用了 **RSNNS** 软件包来使用 SNNS 构建神经网络模型。不过，这个模拟器在已经不更新了。作者推荐使用 TensorFlow 或 PyTorch。

TensorFlow 是一个端到端开源机器学习平台
借助 TensorFlow，初学者和专家可以轻松地创建机器学习模型。

```{r eval = FALSE}
install.packages("tensorflow")
library(tensorflow)
install_tensorflow(envname = "tensorflow")
install.packages("keras")
```

Keras 是一个用 Python 编写的高级神经网络 API，它能够以 TensorFlow, CNTK, 或者 Theano 作为后端运行。Keras 的开发重点是支持快速的实验。能够以最小的时延把你的想法转换为实验结果，是做好研究的关键。

```{r eval = FALSE}
install.packages("keras")
```


TensorFlow 的高阶 API 基于 Keras API 标准，用于定义和训练神经网络。Keras 通过用户友好的 API 实现快速原型设计、先进技术研究和生产。
