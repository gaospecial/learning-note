# 神经网络 {#neural-network}

## 神经网络的基本概念 {#concept-of-neural-network}

### 神经元

神经元是神经网络的基本单元。一个神经元由输入端、组合函数、激活函数、输出端组成。组合函数和激活函数是神经网络的核心。

```{r fig.cap="神经元的结构"}
knitr::include_graphics("https://vnote-1251564393.cos.ap-chengdu.myqcloud.com/typora-img/20220420092837.png")
```

人工神经元是一个基于生物神经元的数学模型，神经元接受多个输入信息，对它们进行加权求和，再经过一个激活函数处理，然后将这个结果输出。

对于神经网络而言，神经元节点本身相当于一个神经细胞，输入相当于树突，带权重的连接相当于轴突，输出相当于突触[^neural-network-1]。

[^neural-network-1]: 关于神经网络的更多知识，请参见 <https://www.qikegu.com/docs/3719>。

### 多层感知器

多个神经元连接在一起就形成了神经网络。多层感知器是一种常用的神经网络。各个自变量通过输入层的神经元输入到网络，输入层的输出传递给隐藏层，作为后者的输入；数据经过多个隐藏层的传递后，最终被转换后的数据在输出层形成输出值。

多层感知器通常在隐藏层使用线性组合函数和 S 型激活函数，在输出层使用线性组合函数和与因变量相适应的激活函数。

多层感知器可以形成很复杂的非线性模型。只要给予足够的数据、隐藏层和训练时间，含一层隐藏层的多层感知器就能够以任意精确度近似自变量和因变量之间几乎任何形式的函数；使用多个隐藏层可能用更少的隐藏神经元和参数就能形成复杂的非线性模型，提高模型的泛化能力[^neural-network-2]。

[^neural-network-2]: 是指机器学习算法对新鲜样本的适应能力。 学习的目的是学到隐含在数据背后的规律，对具有同一规律的学习集以外的数据，经过训练的网络也能给出合适的输出，该能力称为泛化能力。

除了多层感知器，常见的神经网络还包括：卷积神经网络、循环神经网络等。卷积神经网络（CNN）旨在解决图像识别问题，卷积神经网络在图像识别、推荐系统以及自然语言处理等方面有着广泛的应用。循环神经网络在语音识别、生成图像描述、音乐合成和机器翻译等领域有着广泛的应用。

不同类型的神经网络都是由多个神经元连接而成的，其主要区别在于神经元的连接规则不同。

对于多层感知器而言，其连接规则为：

-   神经元按照层来布局。最左边的输入层，负责接收输入数据；最右边的输出层，负责输出数据。
-   中间是隐藏层，对于外部不可见。隐藏层可以包含多层，大于一层的就被称为深度神经网络，层次越多数据处理能力越强。
-   同一层的神经元之间没有连接。
-   前后两层的所有神经元相连，前层神经元的输出就是后层神经元的输入。
-   每个连接都有一个权值。

```{r}
knitr::include_graphics("https://vnote-1251564393.cos.ap-chengdu.myqcloud.com/typora-img/20220420100007.png")
```

### 组合函数和激活函数

组合函数通常用线性组合函数，其实就是一个简单的按权重加和。

$$u_j = \sum(v_1, ..., v_s) = b_j + \sum_{r=1}^sw_{rj}v_r$$

激活函数是非线性函数，对组合函数的结果进行处理。它的可选类型比较多，主要有：

-   S 型函数

    -   Logistic 函数：$y = \frac{1}{1+e^{-x}} \in (0, 1)$
    -   Tanh 函数（双曲正切函数）：$y = 1 - \frac{2}{1+e^{2x}} \in (-1, 1)$
    -   Eliot 函数（Softsign 函数）：$y = \frac{x}{1+|x|} \in (-1, 1)$
    -   Arctan 函数：$y = \frac{2}{\pi}arctan(x) \in (-1,1)$

-   ReLU 函数（线性整流函数）：\@ref(eq:relu)

$$\begin{equation}
f(x) = 
\begin{cases} 
x  & \text{if } x \geq 0 \\
0  & \text{if } x < 0
\end{cases}
(\#eq:relu)
\end{equation}$$


- Softmax 函数：$y_j = \frac{e^{u_j}}{\sum_{j'=1}^je^{u_{j'}}} \in (0,1)$

与 S 型函数和 ReLu 函数不同，Softmax 函数是多变量输入激活函数。Softmax 与正常的 max 函数不同：max 函数仅输出最大值，但 Softmax 确保较小的值具有较小的概率，并且不会直接丢弃。

这些激活函数都能将组合函数产生的 $(-\infty, \infty)$ 通过单调连续的非线性转换变成有限的输出值。每种函数在运算速度、可微性、输出值等方面存在差异，因此具有不同的应用场景。

### 神经网络的训练

神经网络的训练，就是求解组合函数权重的过程。简单来说就是从基于误差函数，对权重值不断进行修正，最终是误差逐渐趋近为 0 的过程。误差函数越小，模型拟合效果越好。

根据因变量的取值类型，要在输出层选用不同的激活函数。

- 因变量是二值变量或比例，输出层激活函数采用 Logistic 函数；
- 因变量是多种取值的定类变量，输出层激活函数使用 Softmax 函数或 Logistic 函数；
- 因变量是多种取值的定序变量，可将其看做定类变量，或者根据多个输出单元的结果进行定序；
- 因变量为计数变量（事件发生的次数），输出层的激活函数采用指数函数；
- 因变量为取值可正可负的连续变量（如满足正态分布的数值），输出层激活函数采用恒等函数；
- 因变量为非负连续变量（如收入、销售额），通常将因变量进行 Box-Cox 转换后，在使用因变量可正可负的方法。

*这部分内容解释起来比较复杂，暂且略过*

## 使用神经网络预测红酒品质

`ch7_wine.csv` 记录了与红酒品质相关的 12 个变量，分别是：

- fixed.acidity：固定酸度
- volatile.acidity：挥发性酸度
- citric.acid：柠檬酸
- residual.sugar：残留的糖分
- chlorides：氯化物
- free.sulfur.dioxide：游离二氧化硫
- total.sulfur.dioxide：总二氧化硫
- density：密度
- pH：酸碱度
- sulphates：硫酸盐
- alcohol：酒精度
- quality：**因变量**，品质等级，取值 3 - 9。

```{r}
file = xfun::magic_path("ch7_wine.csv")
wine = readr::read_csv(file)
wine
```

### 数据标准化和拆分

将数据集标准化，并采用分层抽样的方法将其分为学习数据集和测试数据集。

```{r}
library(dplyr)
library(sampling)
set.seed(12345)

wine = wine %>%
  mutate_at(vars(-quality), scale) %>%
  mutate(quality = quality - 3) %>%
  arrange(quality)

train_sample = strata(wine, stratanames = "quality",
                      size = round(0.7 * table(wine$quality)),
                      method = "srswor")

wine_train = wine[train_sample$ID_unit,]
wine_test = wine[-train_sample$ID_unit,]
```

生成数据集的自变量矩阵。

```{r}
x_train = wine_train[,1:11] %>% as.matrix()
x_test = wine_test[,1:11] %>% as.matrix()
```

生成数据集的因变量矩阵。因变量矩阵分别指示定类变量和定序变量。

```{r}
library(keras)
y_train.nom = to_categorical(wine_train$quality)
tail(y_train.nom)
```

因为因变量是定序变量，所以可以生成一个定序变量矩阵。在这里，如果一个观测的 quality 取值为 0 时，相应行的取值是 $(1, 0, 0, 0, 0, 0, 0)$；如果取值是 6 时，相应行的取值是 $(1, 1, 1, 1, 1, 1, 1, 1)$。

```{r}
y_train.ord = y_train.nom

for (i in 1:nrow(y_train.ord)){
  j = which(y_train.ord[i,] == 1)
  y_train.ord[i,1:j] = 1
}

tail(y_train.ord)
```

同样生成测试数据集的相应结果。

```{r}
y_test.nom = to_categorical(wine_test$quality)

y_test.ord = y_test.nom

for (i in 1:nrow(y_test.ord)){
  j = which(y_test.ord[i,] == 1)
  y_train.ord[i, 1:j] = 1
}
```



### 构建神经网络

构建神经网络需要先配置模型的层，然后再编译模型。

神经网络的基本组成部分是层。大多数深度学习都包括将简单的层链接在一起。大多数层（如 `layer_Dense()` 指定的层）都具有在训练期间才会学习的参数。

```{r}
model = keras_model_sequential() %>%
  layer_flatten(input_shape = 11) %>%
  layer_dense(units = 128, activation = "relu")  %>%
  # layer_dropout(0.2) %>%
  layer_dense(units = 7, activation = "softmax")

summary(model)
```

该网络的第一层 `layer_flatten()` 将输入数据转换成一维数组（这里是 11 维的向量，如果是 28 * 28 的矩阵，则可以写 `input_shape = c(28, 28)`）。该层没有要学习的参数，它只会重新格式化数据。

接下来是两个密集连接层或全连接层。第一个 `Dense` 层有 128 个节点（或神经元），第二个（也是最后一个）层会返回一个长度为 7 的数组。每个节点都包含一个得分，用来表示当前输入属于 7 个类别中的哪一类。

### 编译模型

在准备对模型进行训练之前，还需要再对其进行一些设置。以下内容是在模型的编译步骤中添加的：

- 损失函数：用于测量模型在训练期间的准确率。您会希望最小化此函数，以便将模型“引导”到正确的方向上。
- 优化器：决定模型如何根据其看到的数据和自身的损失函数进行更新。
- 指标：用于监控训练和测试步骤。以下示例使用了准确率，即被正确分类的比率。

```{r}
model %>%
  compile(
    loss = "categorical_crossentropy",
    optimizer = "adam",
    metrics = "accuracy"
  )
```

### 训练定类模型

```{r}
model %>% 
  fit(
    x = x_train, y = y_train.nom,
    epochs = 10,
    validation_split = 0.3,
    verbose = 2
  )
```

训练神经网络模型需要执行以下步骤：

1.  将训练数据馈送给模型。在本例中，训练数据位于 `wine_train` 中。
2.  模型学习将 11 个自变量和 1 个因变量（品质）关联起来。
3.  要求模型对测试集（在本例中为 `wine_test` 数组）进行预测。
4.  验证预测是否与 `wine_test` 数组中的品质相匹配。

#### 评估定类准确率

接下来，比较模型在测试数据集上的表现：

```{r}
model %>%
  evaluate(
    x = x_test,
    y = y_test.nom,
    verbose = 0
  )
```

### 训练定序模型

```{r}
model %>% 
  fit(
    x = x_train, y = y_train.ord,
    epochs = 10,
    validation_split = 0.3,
    verbose = 2
  )

model %>%
  evaluate(
    x = x_test,
    y = y_test.ord,
    verbose = 0
  )
```


结果表明，模型在测试数据集上的准确率略低于训练数据集。训练准确率和测试准确率之间的差距代表过拟合。**过拟合**是指机器学习模型在新的、以前未曾见过的输入上的表现不如在训练数据上的表现。过拟合的模型会“记住”训练数据集中的噪声和细节，从而对模型在新数据上的表现产生负面影响。



```{r}
predictions = predict(model, wine_test[,1:11] %>% as.matrix())
predictions
```

预测结果是自变量在 7 个因变量分类中的概率，使用 `which.max()` 或者 `k_argmax()` 来获得预测的分类。

```{r}
class.prediction = apply(predictions, 1, which.max)
table(wine_test$quality, class.prediction)
```

```{r}
class_pred = model %>% 
  predict(wine_test[,1:11] %>% as.matrix()) %>%
  k_argmax()
class_pred[1:20]
```


### 保存预测模型

使用 `save_model_tf()` 保存神经网络模型，`load_model_tf()` 导入预先创建的神经网络模型。

```{r eval = FALSE}
save_model_tf(object = model, filepath = "model")
reloaded_model = load_model_tf("model")
```



## 安装 TensorFlow

[SNNS](http://www.ra.cs.uni-tuebingen.de/SNNS/welcome.html) 是一个经典的神经网络模拟器，本书采用了 **RSNNS** 软件包来使用 SNNS 构建神经网络模型。不过，这个模拟器在已经不更新了。作者推荐使用 TensorFlow 或 PyTorch。

TensorFlow 是一个端到端开源机器学习平台
借助 TensorFlow，初学者和专家可以轻松地创建机器学习模型。


要安装 TensorFlow，则**必须首先安装 Python/Conda**，参见：<https://docs.anaconda.com/anaconda/install/index.html>。

使用 **tensorflow** 软件包提供的 `install_tensorflow()` 函数可以快速安装 TensorFlow。这里将其安装到一个名为 “tensorflow”的 Conda 环境中。

```{r eval = FALSE}
install.packages("tensorflow")
library(tensorflow)
install_tensorflow(envname = "tensorflow") # 必须首先安装 Python/Conda
```

Keras 是一个用 Python 编写的高级神经网络 API，它能够以 TensorFlow, CNTK, 或者 Theano 作为后端运行。Keras 的开发重点是支持快速的实验。能够以最小的时延把你的想法转换为实验结果，是做好研究的关键。

```{r eval = FALSE}
install.packages("keras")
```

TensorFlow 的高阶 API 基于 Keras API 标准，用于定义和训练神经网络。Keras 通过用户友好的 API 实现快速原型设计、先进技术研究和生产。


### 安装 GPU 支持

**注意**：如果仅学习的话，GPU 支持并非是必须的。

要使用 GPU 加速，则**必须在系统中安装以下 NVIDIA® 软件**：

*   [NVIDIA® GPU 驱动程序](https://www.nvidia.com/drivers) \- CUDA® 11.2 要求 450.80.02 或更高版本。
*   [CUDA® 工具包](https://developer.nvidia.com/cuda-toolkit-archive)：TensorFlow 支持 CUDA® 11.2（TensorFlow 2.5.0 及更高版本）
*   CUDA® 工具包附带的 [CUPTI](http://docs.nvidia.com/cuda/cupti/)。
*   [cuDNN SDK 8.1.0](https://developer.nvidia.com/cudnn) [cuDNN 版本](https://developer.nvidia.com/rdp/cudnn-archive)。
*   （可选）[TensorRT 6.0](https://docs.nvidia.com/deeplearning/tensorrt/archives/index.html#trt_6)，可缩短用某些模型进行推断的延迟时间并提高吞吐量。
