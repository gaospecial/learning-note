<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>第 7 章 线性模型和广义线性模型 | 数据科学学习笔记</title>
<meta name="author" content="高春辉">
<meta name="description" content="线性模型是实际应用中最常用的统计模型。  7.1 模型假设  7.1.1 线性模型假设 经典线性模型的应用是有前提条件的。自变量 \(x = (x_1, ..., x_p)^T\) 被看做是给定的，而因变量 \(Y\) 来自均值为 \(μ\)，方差为 \(σ^2\) 的正态分布 \(N(μ, σ^2)\)，其中 \(μ\) 与 自变量 \(x\) 的关系是： \[μ = \alpha +...">
<meta name="generator" content="bookdown 0.26 with bs4_book()">
<meta property="og:title" content="第 7 章 线性模型和广义线性模型 | 数据科学学习笔记">
<meta property="og:type" content="book">
<meta property="og:description" content="线性模型是实际应用中最常用的统计模型。  7.1 模型假设  7.1.1 线性模型假设 经典线性模型的应用是有前提条件的。自变量 \(x = (x_1, ..., x_p)^T\) 被看做是给定的，而因变量 \(Y\) 来自均值为 \(μ\)，方差为 \(σ^2\) 的正态分布 \(N(μ, σ^2)\)，其中 \(μ\) 与 自变量 \(x\) 的关系是： \[μ = \alpha +...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="第 7 章 线性模型和广义线性模型 | 数据科学学习笔记">
<meta name="twitter:description" content="线性模型是实际应用中最常用的统计模型。  7.1 模型假设  7.1.1 线性模型假设 经典线性模型的应用是有前提条件的。自变量 \(x = (x_1, ..., x_p)^T\) 被看做是给定的，而因变量 \(Y\) 来自均值为 \(μ\)，方差为 \(σ^2\) 的正态分布 \(N(μ, σ^2)\)，其中 \(μ\) 与 自变量 \(x\) 的关系是： \[μ = \alpha +...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">数据科学学习笔记</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">前言</a></li>
<li><a class="" href="rmarkdown.html"><span class="header-section-number">1</span> R Markdown</a></li>
<li class="book-part">微生物生态学</li>
<li><a class="" href="using-vegan.html"><span class="header-section-number">2</span> Vegan 使用技巧</a></li>
<li><a class="" href="probability-statistics.html"><span class="header-section-number">3</span> 概率论和数理统计</a></li>
<li class="book-part">数据挖掘实战</li>
<li><a class="" href="data-mining-practise.html"><span class="header-section-number">4</span> 关于《数据挖掘实战》</a></li>
<li><a class="" href="association-analysis.html"><span class="header-section-number">5</span> 关联规则挖掘</a></li>
<li><a class="" href="clustering-analysis.html"><span class="header-section-number">6</span> 聚类分析</a></li>
<li><a class="active" href="linear-model.html"><span class="header-section-number">7</span> 线性模型和广义线性模型</a></li>
<li><a class="" href="neural-network.html"><span class="header-section-number">8</span> 神经网络</a></li>
<li><a class="" href="decision-tree.html"><span class="header-section-number">9</span> 决策树</a></li>
<li class="book-part">Others</li>
<li><a class="" href="officer.html"><span class="header-section-number">10</span> 处理 Office 文件</a></li>
<li><a class="" href="ggtree-as-phylo-hclust2.html"><span class="header-section-number">11</span> ggtree 代码解析</a></li>
<li><a class="" href="references.html">参考文献</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="linear-model" class="section level1" number="7">
<h1>
<span class="header-section-number">第 7 章</span> 线性模型和广义线性模型<a class="anchor" aria-label="anchor" href="#linear-model"><i class="fas fa-link"></i></a>
</h1>
<p>线性模型是实际应用中最常用的统计模型。</p>
<div id="模型假设" class="section level2" number="7.1">
<h2>
<span class="header-section-number">7.1</span> 模型假设<a class="anchor" aria-label="anchor" href="#%E6%A8%A1%E5%9E%8B%E5%81%87%E8%AE%BE"><i class="fas fa-link"></i></a>
</h2>
<div id="线性模型假设" class="section level3" number="7.1.1">
<h3>
<span class="header-section-number">7.1.1</span> 线性模型假设<a class="anchor" aria-label="anchor" href="#%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E5%81%87%E8%AE%BE"><i class="fas fa-link"></i></a>
</h3>
<p>经典线性模型的应用是有前提条件的。自变量 <span class="math inline">\(x = (x_1, ..., x_p)^T\)</span> 被看做是给定的，而因变量 <span class="math inline">\(Y\)</span> 来自均值为 <span class="math inline">\(μ\)</span>，方差为 <span class="math inline">\(σ^2\)</span> 的正态分布 <span class="math inline">\(N(μ, σ^2)\)</span>，其中 <span class="math inline">\(μ\)</span> 与 自变量 <span class="math inline">\(x\)</span> 的关系是：</p>
<p><span class="math display">\[μ = \alpha + x^T\beta = \alpha + \beta_1x_1 + ... + \beta_px_p\]</span></p>
<p>这里回归系数 <span class="math inline">\(\alpha\)</span> 是截距项，回归系数 <span class="math inline">\(\beta = (\beta_1, ..., \beta_p)^T\)</span> 是对自变量的斜率。</p>
<p>因为线性模型的假设，所以在应用的时候需要进行模型诊断，才能决定适用性。模型诊断需要注意的地方包括：</p>
<ul>
<li>标准化残差图</li>
<li>异常点</li>
<li>自相关性</li>
<li>多重共现性</li>
</ul>
</div>
<div id="广义线性模型假设" class="section level3" number="7.1.2">
<h3>
<span class="header-section-number">7.1.2</span> 广义线性模型假设<a class="anchor" aria-label="anchor" href="#%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E5%81%87%E8%AE%BE"><i class="fas fa-link"></i></a>
</h3>
<p>广义线性模型则推广了线性模型，适用于因变量是定类变量、定序变量等的情形。广义线性模型有 3 个成分，分别是<strong>随机成分</strong>、<strong>系统成分</strong>、<strong>连接函数</strong>。</p>
</div>
</div>
<div id="线性模型预测房屋价格" class="section level2" number="7.2">
<h2>
<span class="header-section-number">7.2</span> 线性模型预测房屋价格<a class="anchor" aria-label="anchor" href="#%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B%E6%88%BF%E5%B1%8B%E4%BB%B7%E6%A0%BC"><i class="fas fa-link"></i></a>
</h2>
<p><code>ch6_house.csv</code> 数据集记录了某地区 21613 座房屋的 10 个变量信息，我们据此可以建立线性模型预测房屋价格。</p>
<p><code>house</code> 数据集的 10 个变量的定义如下：</p>
<ul>
<li>price：房屋价格</li>
<li>bedrooms：卧室数目</li>
<li>bathrooms：卫生间数目</li>
<li>sqft_living：住房面积（平方英尺）</li>
<li>sqft_lot：房基地面积</li>
<li>floors：楼层数目</li>
<li>condition：房屋整体状况的好坏，取值 1 - 5</li>
<li>grade：房屋等级，取值 1 - 13</li>
<li>sqft_above：除地下室以外的住房面积</li>
<li>yr_built：房屋建成年份（最早 1900，最晚 2015）</li>
</ul>
<div class="sourceCode" id="cb292"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://readr.tidyverse.org">readr</a></span><span class="op">)</span></span>
<span><span class="va">file</span> <span class="op">=</span> <span class="fu">xfun</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/xfun/man/magic_path.html">magic_path</a></span><span class="op">(</span><span class="st">"ch6_house.csv"</span><span class="op">)</span></span>
<span><span class="va">house</span> <span class="op">=</span> <span class="fu"><a href="https://readr.tidyverse.org/reference/read_delim.html">read_csv</a></span><span class="op">(</span><span class="va">file</span><span class="op">)</span></span>
<span><span class="va">house</span></span></code></pre></div>
<pre><code>## # A tibble: 21,613 × 10
##      price bedrooms bathr…¹ sqft_…² sqft_…³ floors condi…⁴ grade sqft_…⁵ yr_bu…⁶
##      &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;
##  1  221900        3    1       1180    5650      1       3     7    1180    1955
##  2  538000        3    2.25    2570    7242      2       3     7    2170    1951
##  3  180000        2    1        770   10000      1       3     6     770    1933
##  4  604000        4    3       1960    5000      1       5     7    1050    1965
##  5  510000        3    2       1680    8080      1       3     8    1680    1987
##  6 1230000        4    4.5     5420  101930      1       3    11    3890    2001
##  7  257500        3    2.25    1715    6819      2       3     7    1715    1995
##  8  291850        3    1.5     1060    9711      1       3     7    1060    1963
##  9  229500        3    1       1780    7470      1       3     7    1050    1960
## 10  323000        3    2.5     1890    6560      2       3     7    1890    2003
## # … with 21,603 more rows, and abbreviated variable names ¹​bathrooms,
## #   ²​sqft_living, ³​sqft_lot, ⁴​condition, ⁵​sqft_above, ⁶​yr_built
## # ℹ Use `print(n = ...)` to see more rows</code></pre>
<p>房屋价格变量本身是不符合正态分布的，将其进行转换后符合正态分布。（为什么？）</p>

<div class="sourceCode" id="cb294"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="va">house</span><span class="op">$</span><span class="va">price</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/qqnorm.html">qqnorm</a></span><span class="op">(</span><span class="va">house</span><span class="op">$</span><span class="va">price</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/hist.html">hist</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">house</span><span class="op">$</span><span class="va">price</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/qqnorm.html">qqnorm</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">house</span><span class="op">$</span><span class="va">price</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:house-price-dist"></span>
<img src="leaning-note_files/figure-html/house-price-dist-1.png" alt="转换前后房屋价格的直方图和 QQ 图" width="672"><p class="caption">
图 7.1: 转换前后房屋价格的直方图和 QQ 图
</p>
</div>
<div id="对房屋数据进行标准化" class="section level3" number="7.2.1">
<h3>
<span class="header-section-number">7.2.1</span> 对房屋数据进行标准化<a class="anchor" aria-label="anchor" href="#%E5%AF%B9%E6%88%BF%E5%B1%8B%E6%95%B0%E6%8D%AE%E8%BF%9B%E8%A1%8C%E6%A0%87%E5%87%86%E5%8C%96"><i class="fas fa-link"></i></a>
</h3>
<p>将 price、sqft_living 等变量均取对数。</p>
<p>同时，因为时间是无限增长的，在建模数据集中出现的时间不同于预测数据集中出现的时间，所以时间无法直接应用于建模。必须对时间变量进行转换。</p>
<div class="sourceCode" id="cb295"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org">dplyr</a></span><span class="op">)</span></span>
<span><span class="va">varname</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"price"</span>, <span class="st">"sqft_living"</span>, <span class="st">"sqft_lot"</span>, <span class="st">"sqft_above"</span><span class="op">)</span></span>
<span><span class="va">house</span> <span class="op">=</span> <span class="va">house</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/across.html">across</a></span><span class="op">(</span><span class="va">varname</span>, <span class="va">log</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/rename.html">rename_with</a></span><span class="op">(</span><span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"log_"</span>,<span class="va">.x</span><span class="op">)</span>, .cols <span class="op">=</span> <span class="va">varname</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>age <span class="op">=</span> <span class="fl">2015</span> <span class="op">-</span> <span class="va">yr_built</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="co"># 对年份进行转换</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">yr_built</span><span class="op">)</span></span></code></pre></div>
<p>将数据集随机划分为学习数据集和测试数据集。</p>
<div class="sourceCode" id="cb296"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">12345</span><span class="op">)</span></span>
<span><span class="va">id_learning</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/arules/man/sample.html">sample</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">house</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fl">0.7</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">house</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">house_learning</span> <span class="op">=</span> <span class="va">house</span><span class="op">[</span><span class="va">id_learning</span>,<span class="op">]</span></span>
<span><span class="va">house_test</span> <span class="op">=</span> <span class="va">house</span><span class="op">[</span><span class="op">-</span><span class="va">id_learning</span>,<span class="op">]</span></span></code></pre></div>
</div>
<div id="拟合线性模型" class="section level3" number="7.2.2">
<h3>
<span class="header-section-number">7.2.2</span> 拟合线性模型<a class="anchor" aria-label="anchor" href="#%E6%8B%9F%E5%90%88%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B"><i class="fas fa-link"></i></a>
</h3>
<p>对学习数据集建立线性模型。使用 <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code> 查看模型系数的估计、残差的统计量、R 方等信息。从输出结果看，模型各自变量的贡献均比较显著，R 方值为 0.64。</p>
<div class="sourceCode" id="cb297"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit.lm</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">log_price</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">house_learning</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">fit.lm</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = log_price ~ ., data = house_learning)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.15983 -0.20963  0.01033  0.20339  1.65555 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)      7.8340456  0.0732372 106.968  &lt; 2e-16 ***
## bedrooms        -0.0433545  0.0035877 -12.084  &lt; 2e-16 ***
## bathrooms        0.0813344  0.0059163  13.748  &lt; 2e-16 ***
## log_sqft_living  0.4887105  0.0160515  30.446  &lt; 2e-16 ***
## log_sqft_lot    -0.0332896  0.0034989  -9.514  &lt; 2e-16 ***
## floors           0.0721198  0.0072678   9.923  &lt; 2e-16 ***
##  [ reached getOption("max.print") -- omitted 4 rows ]
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.3155 on 15119 degrees of freedom
## Multiple R-squared:  0.6406, Adjusted R-squared:  0.6404 
## F-statistic:  2994 on 9 and 15119 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>提取模型的系数估计值。</p>
<div class="sourceCode" id="cb299"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coefficients</a></span><span class="op">(</span><span class="va">fit.lm</span><span class="op">)</span></span></code></pre></div>
<pre><code>##     (Intercept)        bedrooms       bathrooms log_sqft_living    log_sqft_lot 
##     7.834045552    -0.043354513     0.081334366     0.488710493    -0.033289648 
##          floors       condition           grade  log_sqft_above             age 
##     0.072119815     0.040946870     0.241517661    -0.076794423     0.006058074</code></pre>
<p>提取模型的系数置信区间，<code>level = 0.95</code> 表示提取 95% 置信区间。</p>
<div class="sourceCode" id="cb301"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html">confint</a></span><span class="op">(</span><span class="va">fit.lm</span>, level <span class="op">=</span> <span class="fl">0.95</span><span class="op">)</span></span></code></pre></div>
<pre><code>##                        2.5 %       97.5 %
## (Intercept)      7.690491718  7.977599387
## bedrooms        -0.050386772 -0.036322253
## bathrooms        0.069737781  0.092930951
## log_sqft_living  0.457247630  0.520173356
## log_sqft_lot    -0.040147996 -0.026431301
## floors           0.057873956  0.086365675
## condition        0.032523068  0.049370673
## grade            0.234395589  0.248639733
## log_sqft_above  -0.106385018 -0.047203827
## age              0.005833631  0.006282517</code></pre>
<p>提取模型的因变量拟合值和残差。</p>
<div class="sourceCode" id="cb303"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">yhat</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/fitted.values.html">fitted</a></span><span class="op">(</span><span class="va">fit.lm</span><span class="op">)</span></span>
<span><span class="va">resid</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/residuals.html">residuals</a></span><span class="op">(</span><span class="va">fit.lm</span><span class="op">)</span></span></code></pre></div>
</div>
<div id="线性模型的模型诊断" class="section level3" number="7.2.3">
<h3>
<span class="header-section-number">7.2.3</span> 线性模型的模型诊断<a class="anchor" aria-label="anchor" href="#%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%A8%A1%E5%9E%8B%E8%AF%8A%E6%96%AD"><i class="fas fa-link"></i></a>
</h3>
<p>图 <a href="linear-model.html#fig:lm-plot">7.2</a> 中：</p>
<p>左上是残差对拟合值的散点图。图中黑线表明，除了拟合值比较小的少部分数据点，残差的平均值接近于零，因而满足线性假设；对于不同的拟合值，残差围绕平均值变化的范围相当，因而满足同方差假设。</p>
<p>右上是标准化残差的正态 QQ 图。可以看出残差大致符合正态分布，但也有少数异常值偏离较大。</p>
<p>左下是标准化残差绝对值的平方根对拟合值的散点图，也可用于更方便的检查同方差假设是否成立。在本例中，大部分的数据点拟合值落在 [12, 15] 区间，在这一区间同方差假设是成立的（黑线水平，且黑线上下点的变化范围接近）。</p>
<p>右下是各观测的 Cook 距离图。从中可见，学习数据中的 5710 号观测点是异常点。</p>

<div class="sourceCode" id="cb304"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span>,</span>
<span>    mar <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2.5</span>, <span class="fl">2.5</span>, <span class="fl">1.5</span>, <span class="fl">1.5</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">fit.lm</span>, which <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:lm-plot"></span>
<img src="leaning-note_files/figure-html/lm-plot-1.png" alt="对线性模型进行诊断。" width="672"><p class="caption">
图 7.2: 对线性模型进行诊断。
</p>
</div>
</div>
<div id="优化线性模型" class="section level3" number="7.2.4">
<h3>
<span class="header-section-number">7.2.4</span> 优化线性模型<a class="anchor" aria-label="anchor" href="#%E4%BC%98%E5%8C%96%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B"><i class="fas fa-link"></i></a>
</h3>
<p>将异常点去掉，重新拟合线性模型。异常值就没有那么大了（图 <a href="linear-model.html#fig:lm2-plot">7.3</a>）。</p>

<div class="sourceCode" id="cb305"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit2.lm</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">log_price</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">house_learning</span><span class="op">[</span><span class="op">-</span><span class="fl">5710</span>,<span class="op">]</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">2</span><span class="op">)</span>,</span>
<span>    mar <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2.5</span>, <span class="fl">2.5</span>, <span class="fl">1.5</span>, <span class="fl">1.5</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">fit2.lm</span>, which <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">4</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:lm2-plot"></span>
<img src="leaning-note_files/figure-html/lm2-plot-1.png" alt="对去除 1 个异常值后的新线性模型进行诊断。" width="672"><p class="caption">
图 7.3: 对去除 1 个异常值后的新线性模型进行诊断。
</p>
</div>
<p>使用所得的线性模型对测试数据集进行预测，计算均方根误差，查看预测价格与实际价格的偏差。</p>
<div class="sourceCode" id="cb306"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pred.lm</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">fit2.lm</span>, <span class="va">house_test</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># 均方根误差</span></span>
<span><span class="va">rmse.lm</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">pred.lm</span><span class="op">)</span><span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">house_test</span><span class="op">$</span><span class="va">log_price</span><span class="op">)</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># x 轴预测价格，y 轴实际价格</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">pred.lm</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">house_test</span><span class="op">$</span><span class="va">log_price</span><span class="op">)</span><span class="op">)</span> </span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>a <span class="op">=</span> <span class="fl">0</span>, b <span class="op">=</span> <span class="fl">1</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="leaning-note_files/figure-html/unnamed-chunk-103-1.png" width="672" style="display: block; margin: auto;"></div>
</div>
</div>
<div id="逻辑回归预测是否患糖尿病" class="section level2" number="7.3">
<h2>
<span class="header-section-number">7.3</span> 逻辑回归预测是否患糖尿病<a class="anchor" aria-label="anchor" href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E9%A2%84%E6%B5%8B%E6%98%AF%E5%90%A6%E6%82%A3%E7%B3%96%E5%B0%BF%E7%97%85"><i class="fas fa-link"></i></a>
</h2>
<p><code>ch6_diabetes.csv</code> 数据集记录了 768 位印第安女性的糖尿病患病资料。</p>
<ul>
<li>Pregnacies：怀孕次数</li>
<li>Glucose：餐后 2 h 血糖</li>
<li>BloodPressure：舒张压（mmHg）</li>
<li>SkinThickness：肱三头肌皮褶厚度（mm）</li>
<li>Insulin：餐后 2 h 的胰岛素水平</li>
<li>BMI：体重指数</li>
<li>DiabetesPredigreeFunction：糖尿病谱系功能</li>
<li>Age：年龄</li>
<li>Outcome：因变量，1 表示有糖尿病，0 表示不患病。</li>
</ul>
<div class="sourceCode" id="cb307"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">file</span> <span class="op">=</span> <span class="fu">xfun</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/xfun/man/magic_path.html">magic_path</a></span><span class="op">(</span><span class="st">"ch6_diabetes.csv"</span><span class="op">)</span></span>
<span><span class="va">diabetes</span> <span class="op">=</span> <span class="fu"><a href="https://readr.tidyverse.org/reference/read_delim.html">read_csv</a></span><span class="op">(</span><span class="va">file</span><span class="op">)</span></span>
<span><span class="va">diabetes</span></span></code></pre></div>
<pre><code>## # A tibble: 768 × 9
##    Pregnancies Glucose BloodPressure SkinT…¹ Insulin   BMI Diabe…²   Age Outcome
##          &lt;dbl&gt;   &lt;dbl&gt;         &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;
##  1           6     148            72      35       0  33.6   0.627    50       1
##  2           1      85            66      29       0  26.6   0.351    31       0
##  3           8     183            64       0       0  23.3   0.672    32       1
##  4           1      89            66      23      94  28.1   0.167    21       0
##  5           0     137            40      35     168  43.1   2.29     33       1
##  6           5     116            74       0       0  25.6   0.201    30       0
##  7           3      78            50      32      88  31     0.248    26       1
##  8          10     115             0       0       0  35.3   0.134    29       0
##  9           2     197            70      45     543  30.5   0.158    53       1
## 10           8     125            96       0       0   0     0.232    54       1
## # … with 758 more rows, and abbreviated variable names ¹​SkinThickness,
## #   ²​DiabetesPedigreeFunction
## # ℹ Use `print(n = ...)` to see more rows</code></pre>
<div id="分层拆分糖尿病患病数据集" class="section level3" number="7.3.1">
<h3>
<span class="header-section-number">7.3.1</span> 分层拆分糖尿病患病数据集<a class="anchor" aria-label="anchor" href="#%E5%88%86%E5%B1%82%E6%8B%86%E5%88%86%E7%B3%96%E5%B0%BF%E7%97%85%E6%82%A3%E7%97%85%E6%95%B0%E6%8D%AE%E9%9B%86"><i class="fas fa-link"></i></a>
</h3>
<p><strong>sampling</strong><span class="citation">(<a href="references.html#ref-R-sampling" role="doc-biblioref">Tillé and Matei 2021</a>)</span> 包有各种抽样函数，可用于分层抽样将数据集分为学习数据集和测试数据集。这里使用 <code><a href="https://rdrr.io/pkg/sampling/man/strata.html">strata()</a></code> 函数分层取 70% 的数据作为学习数据集。参数 <code>stratanames</code> 指定了分层变量的名字；参数 <code>size</code> 给出每层随机抽取的观测数；参数 <code>method = "srswor"</code> 说明在每层中使用无放回的简单随机抽样。</p>
<p><code>learning_sample$ID_unit</code> 给出了抽样得到的结果，可用于获取拆分后的数据集。</p>
<div class="sourceCode" id="cb309"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">12345</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">sampling</span><span class="op">)</span></span>
<span></span>
<span><span class="va">diabetes</span> <span class="op">=</span> <span class="va">diabetes</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="co"># 分层抽样需要将分层变量排序后才能进行</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/arrange.html">arrange</a></span><span class="op">(</span><span class="va">Outcome</span><span class="op">)</span></span>
<span></span>
<span><span class="va">learning_sample</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/sampling/man/strata.html">strata</a></span><span class="op">(</span><span class="va">diabetes</span>, stratanames <span class="op">=</span> <span class="op">(</span><span class="st">"Outcome"</span><span class="op">)</span>,</span>
<span>                         size <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fl">0.7</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">diabetes</span><span class="op">$</span><span class="va">Outcome</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                         method <span class="op">=</span> <span class="st">"srswor"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># 学习数据集</span></span>
<span><span class="va">diabetes_learning</span> <span class="op">=</span> <span class="va">diabetes</span><span class="op">[</span><span class="va">learning_sample</span><span class="op">$</span><span class="va">ID_unit</span>,<span class="op">]</span></span>
<span></span>
<span><span class="co"># 测试数据集</span></span>
<span><span class="va">diabetes_test</span> <span class="op">=</span> <span class="va">diabetes</span><span class="op">[</span><span class="op">-</span><span class="va">learning_sample</span><span class="op">$</span><span class="va">ID_unit</span>,<span class="op">]</span></span></code></pre></div>
</div>
<div id="模型拟合和验证" class="section level3" number="7.3.2">
<h3>
<span class="header-section-number">7.3.2</span> 模型拟合和验证<a class="anchor" aria-label="anchor" href="#%E6%A8%A1%E5%9E%8B%E6%8B%9F%E5%90%88%E5%92%8C%E9%AA%8C%E8%AF%81"><i class="fas fa-link"></i></a>
</h3>
<p>使用 <code><a href="https://rdrr.io/r/stats/glm.html">glm()</a></code> 拟合广义线性模型。<code>family = "binomial"</code> 指定了连接函数的类型（因变量分布为二项分布），从而得到一个 Logit 模型。</p>
<div class="sourceCode" id="cb310"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fit.logit</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">Outcome</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">diabetes_learning</span>,</span>
<span>                family <span class="op">=</span> <span class="st">"binomial"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">fit.logit</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = Outcome ~ ., family = "binomial", data = diabetes_learning)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.3442  -0.7207  -0.4096   0.7434   2.2946  
## 
## Coefficients:
##                           Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)              -8.289674   0.848811  -9.766  &lt; 2e-16 ***
## Pregnancies               0.124052   0.038682   3.207  0.00134 ** 
## Glucose                   0.037027   0.004547   8.144 3.83e-16 ***
## BloodPressure            -0.017535   0.006206  -2.825  0.00472 ** 
## SkinThickness             0.005478   0.008023   0.683  0.49476    
## Insulin                  -0.001491   0.001046  -1.426  0.15389    
##  [ reached getOption("max.print") -- omitted 3 rows ]
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 696.28  on 537  degrees of freedom
## Residual deviance: 505.64  on 529  degrees of freedom
## AIC: 523.64
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<p>将 Logit 模型应用于测试数据集对因变量进行预测。<code>type = "response"</code> 指定预测值为因变量取 1 的概率，并使用概率是否大于 0.5 为分界线，预测因变量类别为 1 或 0。</p>
<div class="sourceCode" id="cb312"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">test.pred.logit</span> <span class="op">=</span> <span class="fl">1</span> <span class="op">*</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">fit.logit</span>, <span class="va">diabetes_test</span>, type <span class="op">=</span> <span class="st">"response"</span><span class="op">)</span> <span class="op">&gt;</span> <span class="fl">0.5</span><span class="op">)</span></span></code></pre></div>
<p>查看因变量真实值域预测值的列联表。真实值为 0（未患病）的有 134 例被预测为 0，16 例被预测为 1；真实值为 1（患病）的有 36 例被预测为 0，44 例被预测为 1。整个模型的预测准确性堪忧。</p>
<div class="sourceCode" id="cb313"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">diabetes_test</span><span class="op">$</span><span class="va">Outcome</span>, <span class="va">test.pred.logit</span><span class="op">)</span></span></code></pre></div>
<pre><code>##    test.pred.logit
##       0   1
##   0 134  16
##   1  36  44</code></pre>
<p>使用 LASSO 算法<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;在统计学和机器学习中，Lasso 算法（Least Absolute Shrinkage and Selection Operator，又译最小绝对值收敛和选择算子、套索算法）是一种同时进行特征选择和正则化（数学）的回归分析方法，旨在增强统计模型的预测准确性和可解释性。&lt;/p&gt;"><sup>3</sup></a> 进行变量选择可以得到最佳模型。因为最佳模型与原模型的效果差别不大，所以不再赘述。</p>
</div>
</div>
<div id="逻辑回归分析预测手机用户流失" class="section level2" number="7.4">
<h2>
<span class="header-section-number">7.4</span> 逻辑回归分析预测手机用户流失<a class="anchor" aria-label="anchor" href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90%E9%A2%84%E6%B5%8B%E6%89%8B%E6%9C%BA%E7%94%A8%E6%88%B7%E6%B5%81%E5%A4%B1"><i class="fas fa-link"></i></a>
</h2>
<p>本部分使用的移动运营商数据有多个数据集构成，分别记录了某移动运营商流失客户的信息和使用行为，以及未流失客户的信息和使用行为。</p>
<div id="读取预处理好的数据集" class="section level3" number="7.4.1">
<h3>
<span class="header-section-number">7.4.1</span> 读取预处理好的数据集<a class="anchor" aria-label="anchor" href="#%E8%AF%BB%E5%8F%96%E9%A2%84%E5%A4%84%E7%90%86%E5%A5%BD%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86"><i class="fas fa-link"></i></a>
</h3>
<p>在进行广义线性模型回归分析前，已经对数据进行了分层抽样，并将建模数据集分为学习数据集和测试数据集，并在学习数据集中通过<strong>欠抽样</strong>抽取了 10 个样本数据集 <a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;抽样是解决样本分布不均衡相对简单且常用的方法，包括过抽样和欠抽样两种。过抽样（也叫上采样，over-sampling）方法通过增加分类中少数类样本的数量来实现样本均衡，最直接的方法是简单复制少数类样本形成多条记录，这种方法的缺点是如果样本特征少而可能导致过拟合的问题；经过改进的过抽样方法通过在少数类中加入随机噪声、干扰数据或通过一定规则产生新的合成样本。欠抽样（也叫下采样，under-sampling）方法通过减少分类中多数类样本的样本数量来实现样本均衡，最直接的方法是随机地去掉一些多数类样本来减小多数类的规模，缺点是会丢失多数类样本中的一些重要信息。（作者：宋天龙；链接：&lt;a href="https://www.zhihu.com/question/66408862/answer/245813803" class="uri"&gt;https://www.zhihu.com/question/66408862/answer/245813803&lt;/a&gt;）&lt;/p&gt;'><sup>4</sup></a>。</p>
<div class="sourceCode" id="cb315"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># 读取 10 个学习数据集</span></span>
<span><span class="va">learn</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/vector.html">vector</a></span><span class="op">(</span>mode <span class="op">=</span> <span class="st">"list"</span>, <span class="fl">10</span><span class="op">)</span></span>
<span><span class="kw">for</span> <span class="op">(</span><span class="va">k</span> <span class="kw">in</span> <span class="fl">1</span><span class="op">:</span><span class="fl">10</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="va">file</span> <span class="op">=</span> <span class="fu">xfun</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/xfun/man/magic_path.html">magic_path</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"ch3_mobile_learning_sample"</span>, <span class="va">k</span>, <span class="st">"_imputed.csv"</span><span class="op">)</span><span class="op">)</span></span>
<span>  <span class="va">learn</span><span class="op">[[</span><span class="va">k</span><span class="op">]</span><span class="op">]</span> <span class="op">=</span> <span class="fu"><a href="https://readr.tidyverse.org/reference/read_delim.html">read_csv</a></span><span class="op">(</span><span class="va">file</span>, locale <span class="op">=</span> <span class="fu"><a href="https://readr.tidyverse.org/reference/locale.html">locale</a></span><span class="op">(</span>encoding <span class="op">=</span> <span class="st">"GB2312"</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/arrange.html">arrange</a></span><span class="op">(</span><span class="va">`设备编码`</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="co"># 读取 10 个测试数据集</span></span>
<span><span class="va">test</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">10</span>, <span class="kw">function</span><span class="op">(</span><span class="va">k</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste0</a></span><span class="op">(</span><span class="st">"ch3_mobile_test_sample"</span>, <span class="va">k</span>, <span class="st">"_imputed.csv"</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu">xfun</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/xfun/man/magic_path.html">magic_path</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://readr.tidyverse.org/reference/read_delim.html">read_csv</a></span><span class="op">(</span>locale <span class="op">=</span> <span class="fu"><a href="https://readr.tidyverse.org/reference/locale.html">locale</a></span><span class="op">(</span>encoding <span class="op">=</span> <span class="st">"GB2312"</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/arrange.html">arrange</a></span><span class="op">(</span><span class="va">`设备编码`</span><span class="op">)</span></span>
<span><span class="op">}</span><span class="op">)</span></span></code></pre></div>
</div>
<div id="建立均值逻辑回归模型" class="section level3" number="7.4.2">
<h3>
<span class="header-section-number">7.4.2</span> 建立（均值）逻辑回归模型<a class="anchor" aria-label="anchor" href="#%E5%BB%BA%E7%AB%8B%E5%9D%87%E5%80%BC%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><i class="fas fa-link"></i></a>
</h3>
<p>根据学习数据集的每个插补后样本数据集建立逻辑模型。使用去掉 <code>设备编码</code> 后的数据集为输入，以 <code>是否流失</code> 为因变量，其它变量为自变量，<code>family = "binomial"</code> 指定因变量分布为二项分布。</p>
<div class="sourceCode" id="cb316"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://glmnet.stanford.edu">glmnet</a></span><span class="op">)</span></span>
<span><span class="va">fit.logit</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">10</span>, <span class="kw">function</span><span class="op">(</span><span class="va">k</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="co"># 逻辑回归模型</span></span>
<span>   <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span> <span class="va">`是否流失`</span> <span class="op">~</span> <span class="va">.</span>, </span>
<span>                   data <span class="op">=</span> <span class="va">learn</span><span class="op">[[</span><span class="va">k</span><span class="op">]</span><span class="op">]</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">-</span><span class="va">`设备编码`</span><span class="op">)</span>,</span>
<span>                   family <span class="op">=</span> <span class="st">"binomial"</span><span class="op">)</span></span>
<span><span class="op">}</span><span class="op">)</span></span></code></pre></div>
<p>将根据学习数据集的 10 个插补后数据集分别建立模型所得的 10 组预测流失概率进行平均，得到测试数据集的预测流失概率。</p>
<div class="sourceCode" id="cb317"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">prob.logit.set</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">10</span>, <span class="kw">function</span><span class="op">(</span><span class="va">k</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="co"># 将模型应用于相应的测试数据集</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">fit.logit</span><span class="op">[[</span><span class="va">k</span><span class="op">]</span><span class="op">]</span>, <span class="va">test</span><span class="op">[[</span><span class="va">k</span><span class="op">]</span><span class="op">]</span>, type <span class="op">=</span> <span class="st">"response"</span><span class="op">)</span></span>
<span><span class="op">}</span><span class="op">)</span></span>
<span><span class="va">prob.logit</span> <span class="op">=</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/bind.html">bind_rows</a></span><span class="op">(</span><span class="va">prob.logit.set</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/colSums.html">colMeans</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
</div>
<div id="计算逻辑回归模型预测的准确率" class="section level3" number="7.4.3">
<h3>
<span class="header-section-number">7.4.3</span> 计算逻辑回归模型预测的准确率<a class="anchor" aria-label="anchor" href="#%E8%AE%A1%E7%AE%97%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B%E7%9A%84%E5%87%86%E7%A1%AE%E7%8E%87"><i class="fas fa-link"></i></a>
</h3>
<p>生成列联表后，分别计算模型预测的准确率。</p>
<div class="sourceCode" id="cb318"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">class.logit</span> <span class="op">=</span> <span class="fl">1</span> <span class="op">*</span> <span class="op">(</span><span class="va">prob.logit</span> <span class="op">&gt;</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span><span class="va">conmat.logit</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">test</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">[[</span><span class="st">"是否流失"</span><span class="op">]</span><span class="op">]</span>, <span class="va">class.logit</span><span class="op">)</span></span>
<span><span class="va">conmat.logit</span></span></code></pre></div>
<pre><code>##    class.logit
##        0    1
##   0 4921  930
##   1   20  136</code></pre>
<div class="sourceCode" id="cb320"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># 未流失用户被正确预测的比例</span></span>
<span><span class="va">accu.y0.logit</span> <span class="op">=</span> <span class="va">conmat.logit</span><span class="op">[</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">]</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">conmat.logit</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># 流失用户被正确预测的比例</span></span>
<span><span class="va">accu.y1.logit</span> <span class="op">=</span> <span class="va">conmat.logit</span><span class="op">[</span><span class="fl">2</span>, <span class="fl">2</span><span class="op">]</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">conmat.logit</span><span class="op">[</span><span class="fl">2</span>, <span class="op">]</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># 所有用户被正确预测的比例</span></span>
<span><span class="va">accu.logit</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/diag.html">diag</a></span><span class="op">(</span><span class="va">conmat.logit</span><span class="op">)</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">conmat.logit</span><span class="op">)</span> <span class="co"># 使用 diag() 取矩阵的对角线数值</span></span></code></pre></div>
</div>
</div>
<div id="lasso-分析预测手机用户流失" class="section level2" number="7.5">
<h2>
<span class="header-section-number">7.5</span> LASSO 分析预测手机用户流失<a class="anchor" aria-label="anchor" href="#lasso-%E5%88%86%E6%9E%90%E9%A2%84%E6%B5%8B%E6%89%8B%E6%9C%BA%E7%94%A8%E6%88%B7%E6%B5%81%E5%A4%B1"><i class="fas fa-link"></i></a>
</h2>
<p>接下来使用 LASSO 分析进行手机用户流失预测，并比较 LASSO 分析得出的模型与逻辑回归模型的准确性。</p>
<p><strong>注意</strong>：LASSO 本身并不等价于线性模型，而是在针对多个变量建模时，为了简化线性模型，用来帮助选择线性模型变量的方法。</p>
<div id="使用学习数据集建立-lasso-回归模型" class="section level3" number="7.5.1">
<h3>
<span class="header-section-number">7.5.1</span> 使用学习数据集建立 LASSO 回归模型<a class="anchor" aria-label="anchor" href="#%E4%BD%BF%E7%94%A8%E5%AD%A6%E4%B9%A0%E6%95%B0%E6%8D%AE%E9%9B%86%E5%BB%BA%E7%AB%8B-lasso-%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><i class="fas fa-link"></i></a>
</h3>
<p>使用 10 个运营商数据插补生成的学习数据集进行建模。<code><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html">cv.glmnet()</a></code> 对 glmnet 模型进行多重交叉验证，然后返回一个 <code>cv.glmnet</code> 类。该类不仅包括预测模型，还包括交叉验证中计算得到的多个成分。</p>
<div class="sourceCode" id="cb321"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cvfit.lasso</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">10</span>, <span class="kw">function</span><span class="op">(</span><span class="va">k</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="co"># 只使用学习数据集中的自变量矩阵</span></span>
<span>  <span class="va">x_learn</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">learn</span><span class="op">[[</span><span class="va">k</span><span class="op">]</span><span class="op">]</span><span class="op">[</span>, <span class="fl">2</span><span class="op">:</span><span class="fl">58</span><span class="op">]</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="co"># 使用交叉验证选出调节参数 lambda 的最佳值</span></span>
<span>  <span class="fu"><a href="https://glmnet.stanford.edu/reference/cv.glmnet.html">cv.glmnet</a></span><span class="op">(</span><span class="va">x_learn</span>, <span class="va">learn</span><span class="op">[[</span><span class="va">k</span><span class="op">]</span><span class="op">]</span><span class="op">[[</span><span class="st">'是否流失'</span><span class="op">]</span><span class="op">]</span>,</span>
<span>            family <span class="op">=</span> <span class="st">"binomial"</span>,</span>
<span>            type.measure <span class="op">=</span> <span class="st">"class"</span><span class="op">)</span></span>
<span><span class="op">}</span><span class="op">)</span></span></code></pre></div>
<p>将模型应用于相应的插补后测试数据集进行预测，并计算 LASSO 模型的回归系数。</p>
<div class="sourceCode" id="cb322"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">prob.lasso</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">10</span>, <span class="kw">function</span><span class="op">(</span><span class="va">k</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="va">x_test</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="va">test</span><span class="op">[[</span><span class="va">k</span><span class="op">]</span><span class="op">]</span><span class="op">[</span>, <span class="fl">2</span><span class="op">:</span><span class="fl">58</span><span class="op">]</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">cvfit.lasso</span><span class="op">[[</span><span class="va">k</span><span class="op">]</span><span class="op">]</span>, <span class="va">x_test</span>,</span>
<span>          s <span class="op">=</span> <span class="st">'lambda.min'</span>,</span>
<span>          type <span class="op">=</span> <span class="st">"response"</span><span class="op">)</span></span>
<span><span class="op">}</span><span class="op">)</span></span>
<span></span>
<span><span class="va">coef.lasso</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">10</span>, <span class="kw">function</span><span class="op">(</span><span class="va">k</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">cvfit.lasso</span><span class="op">[[</span><span class="va">k</span><span class="op">]</span><span class="op">]</span>, s <span class="op">=</span> <span class="st">'lambda.min'</span><span class="op">)</span><span class="op">)</span><span class="op">[</span>, <span class="fl">1</span><span class="op">]</span></span>
<span><span class="op">}</span><span class="op">)</span></span></code></pre></div>
</div>
<div id="计算-lasso-模型的预测准确率" class="section level3" number="7.5.2">
<h3>
<span class="header-section-number">7.5.2</span> 计算 LASSO 模型的预测准确率<a class="anchor" aria-label="anchor" href="#%E8%AE%A1%E7%AE%97-lasso-%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%A2%84%E6%B5%8B%E5%87%86%E7%A1%AE%E7%8E%87"><i class="fas fa-link"></i></a>
</h3>
<p>计算 10 个 LASSO 模型平均的预测流失概率，并以概率 0.5 为阈值计算模型的预测准确率。</p>
<div class="sourceCode" id="cb323"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">prob.lasso.mean</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/do.call.html">do.call</a></span><span class="op">(</span><span class="st">"cbind"</span>, <span class="va">prob.lasso</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/colSums.html">rowMeans</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span><span class="va">class.lasso</span> <span class="op">=</span> <span class="fl">1</span> <span class="op">*</span> <span class="op">(</span><span class="va">prob.lasso.mean</span> <span class="op">&gt;</span> <span class="fl">0.5</span><span class="op">)</span></span>
<span><span class="va">conmat.lasso</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">test</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">[[</span><span class="st">"是否流失"</span><span class="op">]</span><span class="op">]</span>, <span class="va">class.lasso</span><span class="op">)</span></span>
<span><span class="va">conmat.lasso</span></span></code></pre></div>
<pre><code>##    class.lasso
##        0    1
##   0 4919  932
##   1   18  138</code></pre>
<p>分别计算不同类型的预测准确度。</p>
<div class="sourceCode" id="cb325"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># 未流失用户被正确预测的比例</span></span>
<span><span class="va">accu.y0.lasso</span> <span class="op">=</span> <span class="va">conmat.lasso</span><span class="op">[</span><span class="fl">1</span>, <span class="fl">1</span><span class="op">]</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">conmat.lasso</span><span class="op">[</span><span class="fl">1</span>, <span class="op">]</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># 流失用户被正确预测的比例</span></span>
<span><span class="va">accu.y1.lasso</span> <span class="op">=</span> <span class="va">conmat.lasso</span><span class="op">[</span><span class="fl">2</span>, <span class="fl">2</span><span class="op">]</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">conmat.lasso</span><span class="op">[</span><span class="fl">2</span>, <span class="op">]</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># 所有用户被正确预测的比例</span></span>
<span><span class="va">accu.lasso</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/diag.html">diag</a></span><span class="op">(</span><span class="va">conmat.lasso</span><span class="op">)</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">conmat.lasso</span><span class="op">)</span> <span class="co"># 使用 diag() 取矩阵的对角线数值</span></span></code></pre></div>
</div>
</div>
<div id="比较逻辑回归模型和-lasso-模型" class="section level2" number="7.6">
<h2>
<span class="header-section-number">7.6</span> 比较逻辑回归模型和 LASSO 模型<a class="anchor" aria-label="anchor" href="#%E6%AF%94%E8%BE%83%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E5%92%8C-lasso-%E6%A8%A1%E5%9E%8B"><i class="fas fa-link"></i></a>
</h2>
<p>上面针对同样的运营商数据，分别建立了逻辑回归模型和 LASSO 模型，这两种模型得到的结果会有什么不同呢？接下来将回答这个问题。</p>
<div id="模型预测准确率的差异" class="section level3" number="7.6.1">
<h3>
<span class="header-section-number">7.6.1</span> 模型预测准确率的差异<a class="anchor" aria-label="anchor" href="#%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B%E5%87%86%E7%A1%AE%E7%8E%87%E7%9A%84%E5%B7%AE%E5%BC%82"><i class="fas fa-link"></i></a>
</h3>
<p>两种预测模型的准确率差异并不大。</p>
<div class="sourceCode" id="cb326"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">accu</span> <span class="op">=</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span></span>
<span>  type <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"未流失用户准确预测比例"</span>, <span class="st">"流失用户准确预测比例"</span>, <span class="st">"所有用户准确预测比例"</span><span class="op">)</span>,</span>
<span>  logit <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">accu.y0.logit</span>, <span class="va">accu.y1.logit</span>, <span class="va">accu.logit</span><span class="op">)</span>,</span>
<span>  lasso <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">accu.y0.lasso</span>, <span class="va">accu.y1.lasso</span>, <span class="va">accu.lasso</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="va">accu</span></span></code></pre></div>
<pre><code>## # A tibble: 3 × 3
##   type                   logit lasso
##   &lt;chr&gt;                  &lt;dbl&gt; &lt;dbl&gt;
## 1 未流失用户准确预测比例 0.841 0.841
## 2 流失用户准确预测比例   0.872 0.885
## 3 所有用户准确预测比例   0.842 0.842</code></pre>
</div>
<div id="模型使用的自变量" class="section level3" number="7.6.2">
<h3>
<span class="header-section-number">7.6.2</span> 模型使用的自变量<a class="anchor" aria-label="anchor" href="#%E6%A8%A1%E5%9E%8B%E4%BD%BF%E7%94%A8%E7%9A%84%E8%87%AA%E5%8F%98%E9%87%8F"><i class="fas fa-link"></i></a>
</h3>
<p>根据方法的原理，可以得出 LASSO 模型使用的自变量可能会比逻辑模型要少一些。因此，下面分别分析每个 LASSO 模型纳入的自变量。</p>
<p>因为运营商数据包含的数据维度多达 57 个，所以在这些模型中实际上纳入的自变量可能是不同的，并且即便是两个模型纳入了同一个自变量，其在模型中的作用也可能是不同的。为了展示这种现象，这里将自变量系数区分为 3 类，大于 0，小于 0 和等于 0。</p>
<div class="sourceCode" id="cb328"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">coef.indic.lasso</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html">lapply</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">10</span>, <span class="kw">function</span><span class="op">(</span><span class="va">k</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="va">coef.lasso</span><span class="op">[[</span><span class="va">k</span><span class="op">]</span><span class="op">]</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span>  <span class="co"># 去掉截距项</span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>    <span class="fu"><a href="https://tibble.tidyverse.org/reference/as_tibble.html">as_tibble</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="op">}</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/bind.html">bind_rows</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate_all.html">mutate_all</a></span><span class="op">(</span> .funs <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">x</span> <span class="op">==</span> <span class="fl">0</span>, <span class="fl">0</span>, <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">x</span> <span class="op">&gt;</span> <span class="fl">0</span>, <span class="fl">1</span>, <span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>可以发现：在 10 个模型中，均为使用的变量就有 8 个，另外有其它变量被模型使用的次数在 1 - 9 之间，而被 10 个模型均纳入的变量只有 6 个。</p>
<div class="sourceCode" id="cb329"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/colSums.html">colSums</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="va">coef.indic.lasso</span><span class="op">)</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/barplot.html">barplot</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="leaning-note_files/figure-html/unnamed-chunk-120-1.png" width="672" style="display: block; margin: auto;"></div>
<p>超过 5 个模型选用的自变量有约 17 个，它们被不同模型使用的情况如下所示。</p>
<div class="sourceCode" id="cb330"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">pheatmap</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">RColorBrewer</span><span class="op">)</span></span>
<span><span class="va">idx</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/which.html">which</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/colSums.html">colSums</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="va">coef.indic.lasso</span><span class="op">)</span><span class="op">)</span> <span class="op">&gt;</span> <span class="fl">5</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/pheatmap/man/pheatmap.html">pheatmap</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html">t</a></span><span class="op">(</span><span class="va">coef.indic.lasso</span><span class="op">[</span>, <span class="va">idx</span><span class="op">]</span><span class="op">)</span>, </span>
<span>         show_rownames <span class="op">=</span> <span class="cn">TRUE</span>, </span>
<span>         show_colnames <span class="op">=</span> <span class="cn">FALSE</span>, </span>
<span>         color <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/grDevices/colorRamp.html">colorRampPalette</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rev.html">rev</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/RColorBrewer/man/ColorBrewer.html">brewer.pal</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">7</span>, name <span class="op">=</span> <span class="st">"RdBu"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">(</span><span class="fl">100</span><span class="op">)</span>,</span>
<span>         breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>, <span class="fl">1</span>, length.out <span class="op">=</span> <span class="fl">100</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="leaning-note_files/figure-html/unnamed-chunk-121-1.png" width="672" style="display: block; margin: auto;"></div>
<p>实际上，即便不使用 LASSO 分析，在广义线性模型中也会报告有哪些自变量在模型中占有更高的权重。<code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code> 输出结果中的最后一列（<code>Pr(&gt;|z|</code>）中，凡是小于 0.05 的都被特别标注了出来，这些便是模型中的主要参量。</p>
<div class="sourceCode" id="cb331"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">fit.logit</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = 是否流失 ~ ., family = "binomial", data = learn[[k]] %&gt;% 
##     select(-设备编码))
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -3.15546  -0.38758  -0.00667   0.39992   2.87340  
## 
## Coefficients:
##                      Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)          15.57839   12.23879   1.273  0.20306    
## 彩铃费                1.19525    3.18991   0.375  0.70789    
## 短信费               -0.40472    0.71838  -0.563  0.57318    
## 本地语音通话费       -0.05480    0.31305  -0.175  0.86105    
## 长途语音通话费        0.15550    0.40991   0.379  0.70442    
## 省内语音漫游费        0.77114    0.38576   1.999  0.04561 *  
##  [ reached getOption("max.print") -- omitted 52 rows ]
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1009.22  on 727  degrees of freedom
## Residual deviance:  434.86  on 670  degrees of freedom
## AIC: 550.86
## 
## Number of Fisher Scoring iterations: 8</code></pre>

</div>
</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="clustering-analysis.html"><span class="header-section-number">6</span> 聚类分析</a></div>
<div class="next"><a href="neural-network.html"><span class="header-section-number">8</span> 神经网络</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#linear-model"><span class="header-section-number">7</span> 线性模型和广义线性模型</a></li>
<li>
<a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E5%81%87%E8%AE%BE"><span class="header-section-number">7.1</span> 模型假设</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E5%81%87%E8%AE%BE"><span class="header-section-number">7.1.1</span> 线性模型假设</a></li>
<li><a class="nav-link" href="#%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E5%81%87%E8%AE%BE"><span class="header-section-number">7.1.2</span> 广义线性模型假设</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B%E6%88%BF%E5%B1%8B%E4%BB%B7%E6%A0%BC"><span class="header-section-number">7.2</span> 线性模型预测房屋价格</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#%E5%AF%B9%E6%88%BF%E5%B1%8B%E6%95%B0%E6%8D%AE%E8%BF%9B%E8%A1%8C%E6%A0%87%E5%87%86%E5%8C%96"><span class="header-section-number">7.2.1</span> 对房屋数据进行标准化</a></li>
<li><a class="nav-link" href="#%E6%8B%9F%E5%90%88%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B"><span class="header-section-number">7.2.2</span> 拟合线性模型</a></li>
<li><a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%A8%A1%E5%9E%8B%E8%AF%8A%E6%96%AD"><span class="header-section-number">7.2.3</span> 线性模型的模型诊断</a></li>
<li><a class="nav-link" href="#%E4%BC%98%E5%8C%96%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B"><span class="header-section-number">7.2.4</span> 优化线性模型</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E9%A2%84%E6%B5%8B%E6%98%AF%E5%90%A6%E6%82%A3%E7%B3%96%E5%B0%BF%E7%97%85"><span class="header-section-number">7.3</span> 逻辑回归预测是否患糖尿病</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#%E5%88%86%E5%B1%82%E6%8B%86%E5%88%86%E7%B3%96%E5%B0%BF%E7%97%85%E6%82%A3%E7%97%85%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="header-section-number">7.3.1</span> 分层拆分糖尿病患病数据集</a></li>
<li><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E6%8B%9F%E5%90%88%E5%92%8C%E9%AA%8C%E8%AF%81"><span class="header-section-number">7.3.2</span> 模型拟合和验证</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90%E9%A2%84%E6%B5%8B%E6%89%8B%E6%9C%BA%E7%94%A8%E6%88%B7%E6%B5%81%E5%A4%B1"><span class="header-section-number">7.4</span> 逻辑回归分析预测手机用户流失</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#%E8%AF%BB%E5%8F%96%E9%A2%84%E5%A4%84%E7%90%86%E5%A5%BD%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="header-section-number">7.4.1</span> 读取预处理好的数据集</a></li>
<li><a class="nav-link" href="#%E5%BB%BA%E7%AB%8B%E5%9D%87%E5%80%BC%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><span class="header-section-number">7.4.2</span> 建立（均值）逻辑回归模型</a></li>
<li><a class="nav-link" href="#%E8%AE%A1%E7%AE%97%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B%E7%9A%84%E5%87%86%E7%A1%AE%E7%8E%87"><span class="header-section-number">7.4.3</span> 计算逻辑回归模型预测的准确率</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#lasso-%E5%88%86%E6%9E%90%E9%A2%84%E6%B5%8B%E6%89%8B%E6%9C%BA%E7%94%A8%E6%88%B7%E6%B5%81%E5%A4%B1"><span class="header-section-number">7.5</span> LASSO 分析预测手机用户流失</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E5%AD%A6%E4%B9%A0%E6%95%B0%E6%8D%AE%E9%9B%86%E5%BB%BA%E7%AB%8B-lasso-%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B"><span class="header-section-number">7.5.1</span> 使用学习数据集建立 LASSO 回归模型</a></li>
<li><a class="nav-link" href="#%E8%AE%A1%E7%AE%97-lasso-%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%A2%84%E6%B5%8B%E5%87%86%E7%A1%AE%E7%8E%87"><span class="header-section-number">7.5.2</span> 计算 LASSO 模型的预测准确率</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#%E6%AF%94%E8%BE%83%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E5%92%8C-lasso-%E6%A8%A1%E5%9E%8B"><span class="header-section-number">7.6</span> 比较逻辑回归模型和 LASSO 模型</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B%E5%87%86%E7%A1%AE%E7%8E%87%E7%9A%84%E5%B7%AE%E5%BC%82"><span class="header-section-number">7.6.1</span> 模型预测准确率的差异</a></li>
<li><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B%E4%BD%BF%E7%94%A8%E7%9A%84%E8%87%AA%E5%8F%98%E9%87%8F"><span class="header-section-number">7.6.2</span> 模型使用的自变量</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>数据科学学习笔记</strong>" was written by 高春辉. It was last built on 2022-07-22.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
