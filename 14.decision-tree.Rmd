# 决策树 {#decision-tree}

决策树根据自变量的值进行递归划分以预测因变量。

如果因变量是分类变量，则称为**分类树**；如果因变量是连续变量，则称为**回归树**。

决策树有以下优点：

- 可以直接处理定类自变量；
- 无需考虑对定序或连续自变量的转换；
- 对自变量的误差和异常值比较稳健，因为决策树只使用连续自变量取值的大小顺序；
- 能够有效的处理缺失值；
- 决策树的规则很容易解释；

同时也有如下缺点：

- 很难发现基于多个变量组合的规则；
- 能达到局部最优，但是无法达到全局最优；
- 树的结构很不稳定。


